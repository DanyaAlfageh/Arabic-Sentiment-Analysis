{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import csv\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "import ArStemmerLib as lib\n",
    "stemmer=  lib.ArStemmer()\n",
    "stemmer.loadDicts([\"general.txt\", \"lex_list.txt\", \"wiki_general.txt\"])\n",
    "stemmer.loadDict(\"wiki_dict.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readNames(filePath):\n",
    "    names=[]\n",
    "    f=open(filePath,'r')\n",
    "    for i in f:\n",
    "        i=i.strip()\n",
    "        names.append(i.lower())\n",
    "    return names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def StopWords(filePath):\n",
    "    stop_words=[]\n",
    "    f=open(filePath,'r',encoding=\"utf-8\") \n",
    "    for i in f:\n",
    "        i=i.strip()\n",
    "        stop_words.append(i)\n",
    "    return stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def removeStopWords(tweet,stop_words):\n",
    "    new_tweet=''\n",
    "    for word in tweet.split():\n",
    "        if word not in stop_words:\n",
    "            new_tweet+=word+' '\n",
    "    return new_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#stem the word\n",
    "def stem(word):\n",
    "    return stemmer.stem(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def removeDuplicates(s):\n",
    "    if s!='':\n",
    "            a=s[0]\n",
    "            for i in s:\n",
    "                if i != a[-1]:\n",
    "                    a=a+i\n",
    "            return  a\n",
    "    else:\n",
    "        return ''\n",
    "removeDuplicates('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def changePolToNum(pol):\n",
    "    if pol=='pos':\n",
    "        return 1\n",
    "    elif pol=='neg':\n",
    "        return -1\n",
    "    else:\n",
    "        return 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preProcessing(tweet):\n",
    "    \n",
    "    \n",
    "    #remove lower for some english words in the tweet\n",
    "    #tweet=tweet.lower()\n",
    "    ##remove links\n",
    "    tweet=re.sub(r\"http\\S+ | www\\S+\" , \"لينك\", tweet)\n",
    "    ##remove # chracter '#messi'-->'messi'\n",
    "    tweet=re.sub(r\"#\" , \"\", tweet)\n",
    "    ##remove mentions (@messi)\n",
    "    tweet=re.sub(r'@\\S+','منشن',tweet)\n",
    "    #remove consecutive chracters from a string ('شكراااااا','شكرا')\n",
    "    tweet=removeDuplicates(tweet)\n",
    "    ##remove stop words()\n",
    "    stop_words=StopWords('negators.txt')\n",
    "    tweet=removeStopWords(tweet,stop_words)\n",
    "    #remove special chracters,#remove words length less than 2 chracters , first and last chracter of a word is not number\n",
    "    tweet=''.join(e+' ' for e in tweet.split() if e.isalnum() and len(e) >= 3 and not(e[0].isdigit() or e[-1].isdigit()))\n",
    "    #stem words\n",
    "    t=''\n",
    "    for i in tweet.split():\n",
    "          t+=stem(i)+' '\n",
    "    tweet=t\n",
    "    \n",
    "    return tweet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data set 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DS1 svm acc  0.385065885798\n",
      "('DS1 svm kernel linear acc ', 0.53440702781844807)\n",
      "DS1 naive  0.472913616398\n",
      "DS1 multinomianl naive  0.543191800878\n"
     ]
    }
   ],
   "source": [
    "with open(\"DS1.csv\", 'r') as file:\n",
    "    train = list(csv.reader(file))\n",
    "train=train[1:] #remove header row\n",
    "train_data=[preProcessing(t[0]) for t in train]\n",
    "train_label=[changePolToNum(t[1]) for t in train]\n",
    "vectorizer = TfidfVectorizer()\n",
    "train_vectors = vectorizer.fit_transform(train_data)\n",
    "\n",
    "with open(\"testData.csv\", 'r') as file:\n",
    "    test = list(csv.reader(file))\n",
    "test=test[1:]\n",
    "test_data=[preProcessing(t[0]) for t in test]\n",
    "test_label=[changePolToNum(t[1]) for t in test]\n",
    "test_vectors = vectorizer.transform(test_data)\n",
    "\n",
    "clf = svm.SVC()\n",
    "clf.fit(train_vectors, train_label)\n",
    "pred=clf.predict(test_vectors)\n",
    "print(\"DS1 svm acc \",accuracy_score(test_label, pred))\n",
    "\n",
    "\n",
    "#kernel svc\n",
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(train_vectors, train_label)\n",
    "pred=clf.predict(test_vectors)\n",
    "print((\"DS1 svm kernel linear acc \",accuracy_score(test_label, pred)))\n",
    "    \n",
    "#naive bayes\n",
    "clf = GaussianNB()\n",
    "clf.fit(train_vectors.toarray(), train_label)\n",
    "pred=clf.predict(test_vectors.toarray())\n",
    "print(\"DS1 naive \",accuracy_score(test_label, pred))     \n",
    "      \n",
    "#multinomial naive bayes\n",
    "clf = MultinomialNB()\n",
    "clf.fit(train_vectors.toarray(), train_label)\n",
    "pred=clf.predict(test_vectors.toarray())\n",
    "print(\"DS1 multinomianl naive \",accuracy_score(test_label, pred))\n",
    "\n",
    "      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DS1 svm acc  0.385065885798\n",
      "('DS1 svm kernel linear acc ', 0.51537335285505126)\n",
      "DS1 naive  0.449487554905\n",
      "DS1 multinomianl naive  0.559297218155\n"
     ]
    }
   ],
   "source": [
    "with open(\"DS1.csv\", 'r') as file:\n",
    "    train = list(csv.reader(file))\n",
    "train=train[1:]\n",
    "train_data=[preProcessing(t[0]) for t in train]\n",
    "train_label=[changePolToNum(t[1]) for t in train]\n",
    "vectorizer = CountVectorizer()\n",
    "train_vectors = vectorizer.fit_transform(train_data)\n",
    "\n",
    "with open(\"testData.csv\", 'r') as file:\n",
    "    test = list(csv.reader(file))\n",
    "test=test[1:]\n",
    "test_data=[preProcessing(t[0]) for t in test]\n",
    "test_label=[changePolToNum(t[1]) for t in test]\n",
    "test_vectors = vectorizer.transform(test_data)\n",
    "\n",
    "clf = svm.SVC()\n",
    "clf.fit(train_vectors, train_label)\n",
    "pred=clf.predict(test_vectors)\n",
    "print(\"DS1 svm acc \",accuracy_score(test_label, pred))\n",
    "\n",
    "\n",
    "#kernel svc\n",
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(train_vectors, train_label)\n",
    "pred=clf.predict(test_vectors)\n",
    "print((\"DS1 svm kernel linear acc \",accuracy_score(test_label, pred)))\n",
    "    \n",
    "#naive bayes\n",
    "clf = GaussianNB()\n",
    "clf.fit(train_vectors.toarray(), train_label)\n",
    "pred=clf.predict(test_vectors.toarray())\n",
    "print(\"DS1 naive \",accuracy_score(test_label, pred))     \n",
    "      \n",
    "#multinomial naive bayes\n",
    "clf = MultinomialNB()\n",
    "clf.fit(train_vectors.toarray(), train_label)\n",
    "pred=clf.predict(test_vectors.toarray())\n",
    "print(\"DS1 multinomianl naive \",accuracy_score(test_label, pred))\n",
    "\n",
    "      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Data set 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DS2 svm acc  0.333821376281\n",
      "DS2 svm kernel linear acc  0.541727672035\n",
      "DS2 naive  0.469985358712\n",
      "DS2 multinomianl naive  0.544655929722\n"
     ]
    }
   ],
   "source": [
    "with open(\"DS2.csv\", 'r') as file:\n",
    "    train = list(csv.reader(file))\n",
    "train=train[1:]\n",
    "train_data=[preProcessing(t[0]) for t in train]\n",
    "train_label=[changePolToNum(t[1]) for t in train]\n",
    "vectorizer = TfidfVectorizer()\n",
    "train_vectors = vectorizer.fit_transform(train_data)\n",
    "\n",
    "with open(\"testData.csv\", 'r') as file:\n",
    "    test = list(csv.reader(file))\n",
    "test=test[1:]\n",
    "test_data=[preProcessing(t[0]) for t in test]\n",
    "test_label=[changePolToNum(t[1]) for t in test]\n",
    "test_vectors = vectorizer.transform(test_data)\n",
    "\n",
    "clf = svm.SVC()\n",
    "clf.fit(train_vectors, train_label)\n",
    "pred=clf.predict(test_vectors)\n",
    "print(\"DS2 svm acc \",accuracy_score(test_label, pred))\n",
    "\n",
    "\n",
    "#kernel svc\n",
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(train_vectors, train_label)\n",
    "pred=clf.predict(test_vectors)\n",
    "print(\"DS2 svm kernel linear acc \",accuracy_score(test_label, pred))\n",
    "    \n",
    "#naive bayes\n",
    "clf = GaussianNB()\n",
    "clf.fit(train_vectors.toarray(), train_label)\n",
    "pred=clf.predict(test_vectors.toarray())\n",
    "print(\"DS2 naive \",accuracy_score(test_label, pred))     \n",
    "      \n",
    "#multinomial naive bayes\n",
    "clf = MultinomialNB()\n",
    "clf.fit(train_vectors.toarray(), train_label)\n",
    "pred=clf.predict(test_vectors.toarray())\n",
    "print(\"DS2 multinomianl naive \",accuracy_score(test_label, pred))\n",
    "\n",
    "      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DS1 svm acc  0.333821376281\n",
      "('DS1 svm kernel linear acc ', 0.53440702781844807)\n",
      "DS1 naive  0.474377745242\n",
      "DS1 multinomianl naive  0.538799414348\n"
     ]
    }
   ],
   "source": [
    "with open(\"DS2.csv\", 'r') as file:\n",
    "    train = list(csv.reader(file))\n",
    "train=train[1:]\n",
    "train_data=[preProcessing(t[0]) for t in train]\n",
    "train_label=[changePolToNum(t[1]) for t in train]\n",
    "vectorizer = CountVectorizer()\n",
    "train_vectors = vectorizer.fit_transform(train_data)\n",
    "\n",
    "with open(\"testData.csv\", 'r') as file:\n",
    "    test = list(csv.reader(file))\n",
    "test=test[1:]\n",
    "test_data=[preProcessing(t[0]) for t in test]\n",
    "test_label=[changePolToNum(t[1]) for t in test]\n",
    "test_vectors = vectorizer.transform(test_data)\n",
    "\n",
    "clf = svm.SVC()\n",
    "clf.fit(train_vectors, train_label)\n",
    "pred=clf.predict(test_vectors)\n",
    "print(\"DS1 svm acc \",accuracy_score(test_label, pred))\n",
    "\n",
    "\n",
    "#kernel svc\n",
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(train_vectors, train_label)\n",
    "pred=clf.predict(test_vectors)\n",
    "print((\"DS1 svm kernel linear acc \",accuracy_score(test_label, pred)))\n",
    "    \n",
    "#naive bayes\n",
    "clf = GaussianNB()\n",
    "clf.fit(train_vectors.toarray(), train_label)\n",
    "pred=clf.predict(test_vectors.toarray())\n",
    "print(\"DS1 naive \",accuracy_score(test_label, pred))     \n",
    "      \n",
    "#multinomial naive bayes\n",
    "clf = MultinomialNB()\n",
    "clf.fit(train_vectors.toarray(), train_label)\n",
    "pred=clf.predict(test_vectors.toarray())\n",
    "print(\"DS1 multinomianl naive \",accuracy_score(test_label, pred))\n",
    "\n",
    "      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data set 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DS3 svm acc  0.385065885798\n",
      "DS3 svm kernel linear acc  0.516837481698\n",
      "DS3 naive  0.433382137628\n",
      "DS3 multinomianl naive  0.537335285505\n"
     ]
    }
   ],
   "source": [
    "with open(\"DS3.csv\", 'r') as file:\n",
    "    train = list(csv.reader(file))\n",
    "train=train[1:]\n",
    "train_data=[preProcessing(t[0]) for t in train]\n",
    "train_label=[changePolToNum(t[1]) for t in train]\n",
    "vectorizer = TfidfVectorizer()\n",
    "train_vectors = vectorizer.fit_transform(train_data)\n",
    "\n",
    "with open(\"testData.csv\", 'r') as file:\n",
    "    test = list(csv.reader(file))\n",
    "test=test[1:]\n",
    "test_data=[preProcessing(t[0]) for t in test]\n",
    "test_label=[changePolToNum(t[1]) for t in test]\n",
    "test_vectors = vectorizer.transform(test_data)\n",
    "\n",
    "clf = svm.SVC()\n",
    "clf.fit(train_vectors, train_label)\n",
    "pred=clf.predict(test_vectors)\n",
    "print(\"DS3 svm acc \",accuracy_score(test_label, pred))\n",
    "\n",
    "\n",
    "#kernel svc\n",
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(train_vectors, train_label)\n",
    "pred=clf.predict(test_vectors)\n",
    "print(\"DS3 svm kernel linear acc \",accuracy_score(test_label, pred))\n",
    "    \n",
    "#naive bayes\n",
    "clf = GaussianNB()\n",
    "clf.fit(train_vectors.toarray(), train_label)\n",
    "pred=clf.predict(test_vectors.toarray())\n",
    "print(\"DS3 naive \",accuracy_score(test_label, pred))     \n",
    "      \n",
    "#multinomial naive bayes\n",
    "clf = MultinomialNB()\n",
    "clf.fit(train_vectors.toarray(), train_label)\n",
    "pred=clf.predict(test_vectors.toarray())\n",
    "print(\"DS3 multinomianl naive \",accuracy_score(test_label, pred))\n",
    "\n",
    "      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DS3 svm acc  0.385065885798\n",
      "DS3 svm kernel linear acc  0.481698389458\n",
      "DS3 naive  0.440702781845\n",
      "DS3 multinomianl naive  0.551976573939\n"
     ]
    }
   ],
   "source": [
    "with open(\"DS3.csv\", 'r') as file:\n",
    "    train = list(csv.reader(file))\n",
    "train=train[1:]\n",
    "train_data=[preProcessing(t[0]) for t in train]\n",
    "train_label=[changePolToNum(t[1]) for t in train]\n",
    "vectorizer = CountVectorizer()\n",
    "train_vectors = vectorizer.fit_transform(train_data)\n",
    "\n",
    "with open(\"testData.csv\", 'r') as file:\n",
    "    test = list(csv.reader(file))\n",
    "test=test[1:]\n",
    "test_data=[preProcessing(t[0]) for t in test]\n",
    "test_label=[changePolToNum(t[1]) for t in test]\n",
    "test_vectors = vectorizer.transform(test_data)\n",
    "\n",
    "clf = svm.SVC()\n",
    "clf.fit(train_vectors, train_label)\n",
    "pred=clf.predict(test_vectors)\n",
    "print(\"DS3 svm acc \",accuracy_score(test_label, pred))\n",
    "\n",
    "\n",
    "#kernel svc\n",
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(train_vectors, train_label)\n",
    "pred=clf.predict(test_vectors)\n",
    "print(\"DS3 svm kernel linear acc \",accuracy_score(test_label, pred))\n",
    "    \n",
    "#naive bayes\n",
    "clf = GaussianNB()\n",
    "clf.fit(train_vectors.toarray(), train_label)\n",
    "pred=clf.predict(test_vectors.toarray())\n",
    "print(\"DS3 naive \",accuracy_score(test_label, pred))     \n",
    "      \n",
    "#multinomial naive bayes\n",
    "clf = MultinomialNB()\n",
    "clf.fit(train_vectors.toarray(), train_label)\n",
    "pred=clf.predict(test_vectors.toarray())\n",
    "print(\"DS3 multinomianl naive \",accuracy_score(test_label, pred))\n",
    "\n",
    "      \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
